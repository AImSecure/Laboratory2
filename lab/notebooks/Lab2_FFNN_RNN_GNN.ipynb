{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AImSecure/Laboratory2/blob/main/lab/notebooks/Lab2_FFNN_RNN_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d244321",
      "metadata": {
        "id": "4d244321"
      },
      "source": [
        "# Laboratory 2 — Model Engineering\n",
        "\n",
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "NXfnBkl-P0ma"
      },
      "id": "NXfnBkl-P0ma"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svE8FspeRPW3",
        "outputId": "5618dabe-bf4f-4009-8492-8d28349f10ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n"
          ]
        }
      ],
      "source": [
        "# --- Check Python and pip versions ---\n",
        "!python --version\n",
        "!pip install --upgrade pip"
      ],
      "id": "svE8FspeRPW3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyfyzIzWbHTG",
        "outputId": "b0471709-166c-4480-efe1-3db80fc0adc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "# --- Install required libraries ---\n",
        "!pip install torch\n",
        "!pip install numpy pandas scikit-learn matplotlib seaborn\n",
        "!pip install tqdm"
      ],
      "id": "fyfyzIzWbHTG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZXgjER_TsGp"
      },
      "outputs": [],
      "source": [
        "# --- Import libraries ---\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "id": "vZXgjER_TsGp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w201oyWVxE9k"
      },
      "source": [
        "### Colab Pro"
      ],
      "id": "w201oyWVxE9k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kIggYNUxFuZ",
        "outputId": "cf4d053f-3a19-446c-b9ad-607cc52171db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "# --- Check GPU availability ---\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "id": "_kIggYNUxFuZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH-w_NELxHpV",
        "outputId": "e0f922d7-e57e-45a9-8f82-e3e650438723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "# --- Check RAM availability ---\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "id": "DH-w_NELxHpV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rFNp6fgTv9w"
      },
      "source": [
        "### Paths setup\n"
      ],
      "id": "2rFNp6fgTv9w"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAnAndzpTxe5",
        "outputId": "cfe8085c-3ecf-4eae-e6bc-82dad76e5fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# --- Mount Google Drive (for Google Colab users) ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "rAnAndzpTxe5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqMS_38yTvFN",
        "outputId": "d7a16987-bce2-4001-8f20-c9ebb88c8640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project path: /content/drive/MyDrive/Projects/AImSecure/Laboratory2/\n",
            "Data path: /content/drive/MyDrive/Projects/AImSecure/Laboratory2/data/\n",
            "Results path: /content/drive/MyDrive/Projects/AImSecure/Laboratory2/results/\n"
          ]
        }
      ],
      "source": [
        "# --- Define Paths ---\n",
        "group = 'AImSecure'\n",
        "laboratory = 'Laboratory2'\n",
        "\n",
        "base_path = '/content/drive/MyDrive/'\n",
        "project_path = base_path + f'Projects/{group}/{laboratory}/'\n",
        "data_path = project_path + 'data/'\n",
        "results_path = project_path + 'results/'\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(project_path, exist_ok=True)\n",
        "os.makedirs(data_path, exist_ok=True)\n",
        "os.makedirs(results_path, exist_ok=True)\n",
        "\n",
        "print(f\"Project path: {project_path}\")\n",
        "print(f\"Data path: {data_path}\")\n",
        "print(f\"Results path: {results_path}\")"
      ],
      "id": "XqMS_38yTvFN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi-G9FFHwZjK"
      },
      "outputs": [],
      "source": [
        "# --- Set visual style ---\n",
        "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n",
        "\n",
        "def save_plot(fig: plt.Figure, filename: str, path: str = \"./plots/\", fmt: str = \"png\", dpi: int = 300, close_fig: bool = False) -> None:\n",
        "    \"\"\"\n",
        "    Save a Matplotlib figure in a specific to a specified directory.\n",
        "\n",
        "    Args:\n",
        "        fig (plt.Figure): Matplotlib figure object to save.\n",
        "        filename (str): Name of the file to save (e.g., 'plot.png').\n",
        "        path (str, optional): Directory path to save the figure. Defaults to './plots/'.\n",
        "        fmt (str, optional): File format for the saved figure. Defaults to 'png'.\n",
        "        dpi (int, optional): Dots per inch for the saved figure. Defaults to 300.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    save_path = os.path.join(path, f\"{filename}.{fmt}\")\n",
        "\n",
        "    # Save the figure\n",
        "    fig.savefig(save_path, bbox_inches='tight', pad_inches=0.1, dpi=dpi, format=fmt)\n",
        "    # plt.close(fig) # Removed to display plots in notebook\n",
        "\n",
        "    if close_fig:\n",
        "        plt.close(fig)\n",
        "\n",
        "    print(f\"Saved plot: {save_path}\")"
      ],
      "id": "pi-G9FFHwZjK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dswv2Je3UA5Y"
      },
      "source": [
        "## Task 1 — Frequency-based baseline\n",
        "\n",
        "We implement a simple frequency-based baseline.  \n",
        "- Transform sequences into feature vectors counting API call occurrences.  \n",
        "- Helps evaluate whether simple approaches already perform well before using complex models.\n"
      ],
      "id": "dswv2Je3UA5Y"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory for plots\n",
        "save_dir = results_path + 'images/' + 'task1_plots/'\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "UbIMFRXuZxMB"
      },
      "id": "UbIMFRXuZxMB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frequency-Based Approach\n",
        "\n",
        "- Extract vocabulary from train and test datasets.\n",
        "- Use vocabulary to create feature vectors (frequency counts per API call).\n",
        "- Output dataframe: one row per sequence, one column per API call."
      ],
      "metadata": {
        "id": "NA3pR682ci7a"
      },
      "id": "NA3pR682ci7a"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h2r7Arn9lfrW"
      },
      "id": "h2r7Arn9lfrW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract the vocabularies"
      ],
      "metadata": {
        "id": "SItC6NaJlciX"
      },
      "id": "SItC6NaJlciX"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Extract vocabulary from training and test sets ---\n",
        "train_vocab = set(api_call for seq in train_sequences for api_call in seq)\n",
        "test_vocab = set(api_call for seq in test_sequences for api_call in seq)"
      ],
      "metadata": {
        "id": "ns8h20polggs"
      },
      "id": "ns8h20polggs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Count unique API calls ---\n",
        "print(f\"Train: {len(train_vocab)}, Test: {len(test_vocab)}\")"
      ],
      "metadata": {
        "id": "1nSi-irym3BB"
      },
      "id": "1nSi-irym3BB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: How many unique API calls does the training set contain? How many in the test set?\n",
        "\n"
      ],
      "metadata": {
        "id": "gKR2C5nZa-9q"
      },
      "id": "gKR2C5nZa-9q"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Identify test-only API calls ---\n",
        "unique_test_only = test_vocab - train_vocab\n",
        "print(f\"Test-only: {len(unique_test_only)}, {unique_test_only}\")"
      ],
      "metadata": {
        "id": "p1honsZym7tU"
      },
      "id": "p1honsZym7tU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Are there any API calls that appear only in the test set (but not in the training set)? If yes, how many? Which ones?"
      ],
      "metadata": {
        "id": "VFaqFS8bbAKH"
      },
      "id": "VFaqFS8bbAKH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### New frequency-based dataframes\n",
        "\n",
        "- Create dataframe using training vocabulary as features.\n",
        "- Count occurrences of each API call per sequence."
      ],
      "metadata": {
        "id": "950319IfljRh"
      },
      "id": "950319IfljRh"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_5Fw9al6llCC"
      },
      "id": "_5Fw9al6llCC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Build frequency-based dataframes ---\n",
        "train_df = pd.DataFrame([{api: seq.count(api) for api in train_vocab} for seq in train_sequences])\n",
        "test_df = pd.DataFrame([{api: seq.count(api) for api in train_vocab} for seq in test_sequences])"
      ],
      "metadata": {
        "id": "M6zhlfEnnj5-"
      },
      "id": "M6zhlfEnnj5-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Can you use the test vocabulary to build the new test dataframe? If not, how do you handle API calls in the test set that do not exist in the training vocabulary?"
      ],
      "metadata": {
        "id": "eijmLDzabFX9"
      },
      "id": "eijmLDzabFX9"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Compute sparsity ---\n",
        "train_nonzeros = train_df.astype(bool).sum(axis=1)\n",
        "test_nonzeros = test_df.astype(bool).sum(axis=1)\n",
        "\n",
        "print(f\"Train avg non-zero: {train_nonzeros.mean():.2f}, Test avg non-zero: {test_nonzeros.mean():.2f}\")\n",
        "print(f\"Ratio train: {train_nonzeros.mean()/len(train_vocab):.2f}, Ratio test: {test_nonzeros.mean()/len(train_vocab):.2f}\")"
      ],
      "metadata": {
        "id": "ZEiDnT4vnmMS"
      },
      "id": "ZEiDnT4vnmMS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: How many non-zero elements per row do you have on average in the training set? How many in the test set? What is the ratio with respect to the number of elements per row?"
      ],
      "metadata": {
        "id": "MeJMVfhPbGa8"
      },
      "id": "MeJMVfhPbGa8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: The original API sequences were ordered. Is it still the case now in the frequency-based dataframe? Why?"
      ],
      "metadata": {
        "id": "zxxQ9ubZbGQd"
      },
      "id": "zxxQ9ubZbGQd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feed the frequency-based datasets to a classifier\n",
        "\n",
        "- Any classifier can be used (shallow/deep neural or non-neural).\n",
        "- Goal: evaluate baseline performance on sparse vectors without sequence information."
      ],
      "metadata": {
        "id": "1auoE5O0lqJX"
      },
      "id": "1auoE5O0lqJX"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MnBZa6Pnlrii"
      },
      "id": "MnBZa6Pnlrii",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example: RandomForest classifier ---\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "clf.fit(train_df, y_train)\n",
        "y_pred = clf.predict(test_df)\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "q_i8zIGCntTQ"
      },
      "id": "q_i8zIGCntTQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Report how you chose the hyperparameters of your classifier, and the final performance on the test set."
      ],
      "metadata": {
        "id": "w-qM18CHbGB5"
      },
      "id": "w-qM18CHbGB5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Is the final performance good, even ignoring the order of API calls and handling very sparse vectors?"
      ],
      "metadata": {
        "id": "SgnC8DmjbFwL"
      },
      "id": "SgnC8DmjbFwL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2 - Feed Forward Neural Network (FFNN)\n",
        "\n",
        "text"
      ],
      "metadata": {
        "id": "ad7SH8cyZ1K_"
      },
      "id": "ad7SH8cyZ1K_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory for plots\n",
        "save_dir = results_path + 'images/' + 'task2_plots/'\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "QRKP-a8gZ1bH"
      },
      "id": "QRKP-a8gZ1bH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### API Call Statistics"
      ],
      "metadata": {
        "id": "hpIwk43BcgpV"
      },
      "id": "hpIwk43BcgpV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Do you have the same number of API calls per sequence? If not, is the distribution of API calls per sequence the same for training and test sets?"
      ],
      "metadata": {
        "id": "jaJDCdvSbkBr"
      },
      "id": "jaJDCdvSbkBr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Can a FFNN handle a variable number of elements? If not, why?"
      ],
      "metadata": {
        "id": "KQ3p_4-XblBt"
      },
      "id": "KQ3p_4-XblBt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fixed-Size Sequences"
      ],
      "metadata": {
        "id": "-1YpgfFGce9i"
      },
      "id": "-1YpgfFGce9i"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: How to estimate a fixed-size candidate? Which partition do you use to estimate it?"
      ],
      "metadata": {
        "id": "F1z-IWJhbk6a"
      },
      "id": "F1z-IWJhbk6a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Given the estimate, what technique could you use to obtain the same number of API calls per sequence?"
      ],
      "metadata": {
        "id": "7mZhjlflbkyG"
      },
      "id": "7mZhjlflbkyG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: If at test time you have more API calls than the fixed-size, what do you do with the exceeding API calls?"
      ],
      "metadata": {
        "id": "Pt9eHesxbkqR"
      },
      "id": "Pt9eHesxbkqR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Categorical Features"
      ],
      "metadata": {
        "id": "ZKDxmJEsccAw"
      },
      "id": "ZKDxmJEsccAw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Use a FFNN in both cases. Report how you selected the hyperparameters of your final model, and justify your choices."
      ],
      "metadata": {
        "id": "r_oeut1cbkiF"
      },
      "id": "r_oeut1cbkiF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Can you obtain the same results for sequential identifiers and learnable embeddings? If not, why?"
      ],
      "metadata": {
        "id": "tlHmv9W7bkUa"
      },
      "id": "tlHmv9W7bkUa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3 - Recursive Neural Network (RNN)\n",
        "\n",
        "text"
      ],
      "metadata": {
        "id": "4tuRqX7NZ1vJ"
      },
      "id": "4tuRqX7NZ1vJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory for plots\n",
        "save_dir = results_path + 'images/' + 'task3_plots/'\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "GBCKFczDZ2Fz"
      },
      "id": "GBCKFczDZ2Fz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequence Modeling with RNNs"
      ],
      "metadata": {
        "id": "KZ7u_SuecZ6E"
      },
      "id": "KZ7u_SuecZ6E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: With RNNs, do you still have to pad your data? If yes, how?"
      ],
      "metadata": {
        "id": "oMn691eJb4K_"
      },
      "id": "oMn691eJb4K_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Do you have to truncate the testing sequences? Justify your answer."
      ],
      "metadata": {
        "id": "E9lZ8tc4b4Et"
      },
      "id": "E9lZ8tc4b4Et"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Is the RNN padding more memory efficient compared to the FFNN’s one? Why?"
      ],
      "metadata": {
        "id": "x0v6KwErb3_D"
      },
      "id": "x0v6KwErb3_D"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Start with a simple one-directional RNN. Is your network as fast as the FFNN? If not, why?"
      ],
      "metadata": {
        "id": "RbLBrMabb34N"
      },
      "id": "RbLBrMabb34N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network Variations"
      ],
      "metadata": {
        "id": "KWX12pVscXTY"
      },
      "id": "KWX12pVscXTY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Is the RNN training as stable as the FFNN's one?"
      ],
      "metadata": {
        "id": "5HXX0DGEb3wq"
      },
      "id": "5HXX0DGEb3wq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: How does your model's performance compare to the simple frequency baseline?"
      ],
      "metadata": {
        "id": "VMCra0eHb3my"
      },
      "id": "VMCra0eHb3my"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4 - Graph Neural Network (GNN)\n",
        "\n",
        "text"
      ],
      "metadata": {
        "id": "McIjNvYYZ2S1"
      },
      "id": "McIjNvYYZ2S1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory for plots\n",
        "save_dir = results_path + 'images/' + 'task4_plots/'\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "Cf1bbg_eZ2rk"
      },
      "id": "Cf1bbg_eZ2rk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling API Sequences as Graphs"
      ],
      "metadata": {
        "id": "sYEN9a_ocRaV"
      },
      "id": "sYEN9a_ocRaV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Do you still have to pad your data? If yes, how?"
      ],
      "metadata": {
        "id": "e0mcrpAbcHrJ"
      },
      "id": "e0mcrpAbcHrJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: Do you have to truncate the testing sequences? Justify your answer."
      ],
      "metadata": {
        "id": "bk8rizi8cHla"
      },
      "id": "bk8rizi8cHla"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: What is the advantage of modeling your problem with a GNN compared to an RNN? What do you lose?"
      ],
      "metadata": {
        "id": "A2QLdRaYcHfL"
      },
      "id": "A2QLdRaYcHfL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GNN Variations"
      ],
      "metadata": {
        "id": "OYdDyge3cTDE"
      },
      "id": "OYdDyge3cTDE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q: How does each model perform compared to the previous architectures? Can you beat the baseline?"
      ],
      "metadata": {
        "id": "8DvvUPSdcHQU"
      },
      "id": "8DvvUPSdcHQU"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}